{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a11c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caption: The image is a promotional poster for the Marvel television series \"Agents of S.H.I.E.L.D.\" featuring six characters standing in front of a large, circular door with the Marvel logo at the top.\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from typing import TypedDict, Optional\n",
    "from PIL import Image\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai import Credentials\n",
    "import base64\n",
    "import os\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    image: bytes\n",
    "    caption: Optional[str]\n",
    "\n",
    "WATSONX_URL = os.getenv(\"WATSONX_URL\")\n",
    "WATSONX_APIKEY = os.getenv(\"WATSONX_APIKEY\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "\n",
    "creds = Credentials(\n",
    "    url=WATSONX_URL,\n",
    "    api_key=WATSONX_APIKEY\n",
    ")\n",
    "\n",
    "vision_model = ModelInference(\n",
    "    model_id=\"meta-llama/llama-3-2-90b-vision-instruct\",\n",
    "    credentials=creds,\n",
    "    project_id=PROJECT_ID\n",
    ")\n",
    "\n",
    "\n",
    "def load_image_node(state: AgentState):\n",
    "    try:\n",
    "        Image.open(io.BytesIO(state[\"image\"]))  # valida\n",
    "    except Exception:\n",
    "        raise ValueError(\"Il file fornito non Ã¨ un'immagine valida.\")\n",
    "    return state\n",
    "\n",
    "\n",
    "def caption_node(state: AgentState):\n",
    "    # Converti immagine in base64\n",
    "    img_b64 = base64.b64encode(state[\"image\"]).decode(\"utf-8\")\n",
    "\n",
    "    # Prompt per la caption\n",
    "    prompt = \"Describe this image in one concise sentence.\"\n",
    "\n",
    "    # Chiamata CORRETTA ai modelli vision\n",
    "    response = vision_model.chat(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\n",
    "                                    \"url\": f\"data:image/jpeg;base64,{img_b64}\",\n",
    "                                }}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    state[\"caption\"] = response[\"choices\"][0][\"message\"]['content']\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "\n",
    "graph.add_node(\"load_image\", load_image_node)\n",
    "graph.add_node(\"caption_image\", caption_node)\n",
    "\n",
    "graph.add_edge(START, \"load_image\")\n",
    "graph.add_edge(\"load_image\", \"caption_image\")\n",
    "graph.add_edge(\"caption_image\", END)\n",
    "\n",
    "app = graph.compile()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    with open(\"agents.jpeg\", \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    out = app.invoke({\"image\": data})\n",
    "    print(\"Caption:\", out[\"caption\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unisa_langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
